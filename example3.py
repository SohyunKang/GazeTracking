import cv2
from gaze_tracking import GazeTracking

# ðŸ”¹ ìž…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
video_path = "ì‹œì„ ë¹„ë””ì˜¤1.mov"   # <- ì—¬ê¸°ì— ë„¤ ë¹„ë””ì˜¤ ê²½ë¡œ

# ðŸ”¹ ì¶œë ¥(ì €ìž¥) ë¹„ë””ì˜¤ ê²½ë¡œ
output_path = "example_annotated.mp4"

gaze = GazeTracking()
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    raise SystemExit

# ì›ë³¸ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
fps = cap.get(cv2.CAP_PROP_FPS)
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# ðŸ”¹ VideoWriter ì„¤ì • (mp4 ì €ìž¥)
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

while True:
    ret, frame = cap.read()
    if not ret:
        print("ðŸŽ¬ ë¹„ë””ì˜¤ ë")
        break

    # GazeTracking ë¶„ì„
    gaze.refresh(frame)
    frame = gaze.annotated_frame()

    # ìƒíƒœ í…ìŠ¤íŠ¸
    text = ""
    if gaze.is_blinking():
        text = "Blinking"
    elif gaze.is_right():
        text = "Looking right"
    elif gaze.is_left():
        text = "Looking left"
    elif gaze.is_center():
        text = "Looking center"

    cv2.putText(
        frame, text, (90, 60),
        cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2
    )

    # ë™ê³µ ì¢Œí‘œ
    left_pupil = gaze.pupil_left_coords()
    right_pupil = gaze.pupil_right_coords()

    cv2.putText(frame, f"Left pupil:  {left_pupil}", (90, 130),
                cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)
    cv2.putText(frame, f"Right pupil: {right_pupil}", (90, 165),
                cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)

    # ðŸ”¹ í”„ë ˆìž„ ì €ìž¥ (annotated ì˜ìƒ)
    out.write(frame)

    # í™”ë©´ì—ë„ ë³´ì—¬ì£¼ê³  ì‹¶ìœ¼ë©´ ìœ ì§€
    cv2.imshow("Gaze Tracking (Video)", frame)
    if cv2.waitKey(1) == 27:  # ESC
        break

cap.release()
out.release()
cv2.destroyAllWindows()

print("âœ… ì €ìž¥ ì™„ë£Œ:", output_path)
